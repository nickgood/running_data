---
title: "Load and model running data"
author: "Nicholas Good"
output:
  pdf_document: default
  html_document:
    theme: paper
---

```{r global_options, include = FALSE}
  knitr::opts_chunk$set(fig.path = 'figures/',
                        warning = FALSE,
                        message = FALSE,
                        fig.width = 6, fig.height = 4,
                        cache = FALSE,
                        echo = TRUE)
```

---

* create a new RMarkdown document for these exercises
* make sure you have a folder with the data for the exercise

## Using functions to load data

1. Write a function to load one of the running .csv files
 * you'll need the `readr` library
 * the function should accept one argument (the name of the file)

2  Update the function load the all columns as class - character
 * you can use the `col_types = cols(.default = "c")` argument with `read_csv`

Example code:

```{r}
library(readr)

read_run_file <- function(file_name){
  read_csv(file_name, col_types = cols(.default = "c"))
}
```

3. Create a vector of the .csv files in the running folder
 * you can use the `list.files` function to do this
 * you'll need to specify a path relative to the new project you created for this exercise
 * using the wrong path is the most common mistake that will cause the function to return `character(0)` instead of the vector of file paths

4. Update the vector of files to include the full path of each file
 * you'll need to include an extra argument in the function call
 
5. Load one of the running files using your load function
 * use indexing to extract the name of the file you wish to load from the vector of file names

Example code:

```{r}
files <- list.files("data/running", ".csv$", full.names = TRUE)

run_file <- read_run_file(files[1])
```

6. Update the file loading function
 * take a look at the file you just loaded, write down the things that need tidying
 * write a function to tidy a character string into a (https://google.github.io/styleguide/Rguide.xml)[stylish R name] , call the function `clean_names`
 * update your file loading function to clean the column names using the `clean_names` function you just wrote
 * filter for only rows that contain data for complete miles using `dplyr::filter()`
 * convert the time strings to `hms` class using `lubridate` and `dplyr::mutate_at()`
 * convert the remaining character columns to numeric class using `dplyr::mutate_if()`
 * add a column containing the file name using `dplyr::mutate()`
 * reload a data file using the updated loading function
 * check the loaded file is formated as expected

Example code:

```{r, include=FALSE}
clean_names <- function(x){gsub(" ", "_", tolower(x))}
```

```{r, warning=FALSE, message=FALSE}
library(lubridate)
library(dplyr)

read_run_file <- function(file){
  read_csv(file, col_types = cols(.default = "c")) %>%
  rename_all(clean_names) %>%
  filter(distance == "1" & split != "Summary") %>%
  mutate_at(vars(matches("time|pace")), hms) %>%
  mutate_if(is.character, as.numeric) %>%
  mutate(file_name = sub(".csv", "", basename(file)))
}

tail(read_run_file(files[1]), 3)
```

7. Load all the .csv files from the running folder
 * use `map()` from the `purrr` package
 * check the class of the loaded object (it should be a list)
 * how many files were loaded?

Example code:

```{r, warning=FALSE}
library(purrr)

all_files <- map(files, read_run_file)
```

```{r}
class(all_files)
```

```{r}
length(all_files)
```

---

## Predicting running times

build a model to predict how long it will take to run this [50 mile race](http://humanpotentialrunning.com/wp-content/uploads/2018/03/Indian-Creek-Elevation-Profiles.pdf) using the running data set.

- first write a function to summarise each training run. Think about what some useful summary statsitics might be. Be sure to include the total distance of each run, average pace, and the file name in your summary.

Example code:

```{r}
run_sum <- function(x){
  summarise(x, 
            distance = sum(distance, na.rm = TRUE),
            gain = sum(elevation_gain, na.rm = TRUE),
            gain_per_mile = mean(elevation_gain, na.rm = TRUE),
            loss_per_mile = mean(elev_loss, na.rm = TRUE),
            loss = sum(elev_loss, na.rm = TRUE),
            pace_mins = mean(as.numeric(avg_pace) / 60, na.rm = TRUE),
            t_min = min(avg_temperature, na.rm = TRUE),
            t_max = max(avg_temperature, na.rm = TRUE),
            t_mean = mean(avg_temperature, na.rm = TRUE),
            file_name = first(file_name))
}
```

- Use `map_df()` to create a data frame summarizing each run.

Example code:

```{r}
library(knitr)

run_summary <- map_df(all_files, run_sum)

class(run_summary)

kable(tail(run_summary, 5), digits = 1)
```

- join the `run_summary` data frame with the elevation data file
- create a new variable for the total time each run takes
- remove the `file_name` column

Example code:

```{r}
library(tidyr)

run_data <- run_summary %>%
            left_join(read_csv("data/elevation.csv", col_types = cols()), by = "file_name") %>%
            mutate(duration = pace_mins * distance) %>%
            select(-file_name)
```

---

## Exploratory analysis

We can use exploratory analyses to come up with candidate explanatory variables for our model.

### Adding new variables

* For example we want to explore it temporal variables predict pace. First, we'll need to extract temperoal information from out `datetime` object:

- add time date, day of week and month variables to the dataset.

Example code:

```{r}
library(lubridate)
run_desc <- run_data %>%
            mutate(date = as.Date(datetime_start),
                   dow = wday(datetime_start, label=TRUE),
                   month = month(datetime_start, label=TRUE))
```

- now plot the time series of pace
- color the plot by total distance
- add a trend line (think about what type of line; linear? quadratic? smoothed?)
- add a theme
- add useful axis labels

Example code:

```{r fig_pace_distance}
library(ggplot2)
library(LaCroixColoR)

ggplot(run_desc %>% mutate(distance = as.factor(distance)), aes(x = datetime_start, y = pace_mins, color = distance)) +
  geom_point(size = 2) +
  scale_color_manual(values = lacroix_palette("PeachPear", n = 27, type = "continuous")) +
  theme_bw() +
  xlab("") + ylab("pace (minutes/mile)") +
  theme(title = element_text(size = 14),
        axis.text = element_text(size = 12)) +
  geom_smooth(methd = "loess", se = FALSE, color = "slategray3", size = 2) +
  ylim(16,5) +
  ggtitle("Pace vs. Date")
```

- make box plots of pace for each day of the week using the `group` argument in the `mapping` aesthetic.
- label the plot and make it look nice!

Example code:

```{r fig_pace_dow}
library(ggplot2)
library(LaCroixColoR)

ggplot(run_desc, aes(x = dow, y = pace_mins, color = dow, group = dow)) +
  geom_boxplot() +
  scale_color_manual(values = lacroix_palette("PassionFruit", n = 7, type = "continuous")) +
  theme_bw() +
  xlab("") + ylab("pace (minutes/mile)") +
  theme(title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.position = "none") +
  ylim(16,4) +
  ggtitle("Pace vs. Day of week")
```

* The box plot indicates that pace tends to be slower on Saturdays.

- Use the `pairs()` function to make a scatter plot matrix between variables of interest
- Would day of week be a useful variable to add to the model?

Example code:

```{r fig_pairs_scatter}
pairs(run_desc %>% select(pace_mins, distance, gain, t_mean, e_max, month, dow))
```

---

- use the (http://mfp.imbi.uni-freiburg.de)[mfp] library to identify the best model to predict duration
- the first argument the `mfp` function requires is a `formula` object. The formula should contain all the candidate variables.
- take a look at the website link above to get an idea what the `mfp` function does.

Example formula :

```{r}
eqn <- formula(duration ~ fp(distance) + fp(gain) + fp(loss) +
                           fp(t_min)+ fp(t_max) + fp(t_mean) +
                           fp(e_min) + fp(e_max) + fp(e_mean))
```

- use the `summary` function to display the output from `mfp`
- use the `$` operator to extract the model formula from the `mfp` object.
- use the model formula to fit a linear model to the running data
- print a summary of the linear model

Example `mfp` code:

```{r}
library(mfp)

mfp_run <- mfp(eqn,
               data = run_data,
               select = 0.05)

summary(mfp_run)

run_mod <- lm(mfp_run$formula, run_data)

summary(run_mod)
```

- you can use the `autoplot` function to check the model diagnostics

```{r}
library(ggfortify)

autoplot(run_mod)
```

- use the model to predict the finishing times for my previous two [races](https://ultrasignup.com/results_participant.aspx?fname=Nicholas&lname=Good&age=35)
- finally use the model to predict [next weekend's race](http://humanpotentialrunning.com/wp-content/uploads/2018/03/Indian-Creek-Elevation-Profiles.pdf) time
- the race has an intermediate cut-off time at mile 34, will I make it?

Example code:

```{r imogene_pass}
pre <- predict.lm(run_mod, data_frame(distance = 17.1, gain = 5420, loss = 4417, t_min = 50))
```

The predicted imogene pass run time was: `r round(seconds_to_period(pre*60), 0)`.

```{r jelm_mountain}
pre <- predict.lm(run_mod, data_frame(distance = 10.2, gain = 2000, loss = 2000, t_min = 55))
```

The predicted imogene pass run time was: `r round(seconds_to_period(pre*60), 0)`.
